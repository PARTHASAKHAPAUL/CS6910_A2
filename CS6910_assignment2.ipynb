{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fe75b8",
   "metadata": {},
   "source": [
    "# **NAME: PARTHA SAKHA PAUL**\n",
    "\n",
    "# **ROLL: MA23M016**\n",
    "\n",
    "    CS6910_assignment 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "730789c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# data_dir = '/content/drive/My Drive/nature_12K'\n",
    "data_dir = 'inaturalist_12K'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# data_dir = '/content/drive/My Drive/nature_12K/inaturalist_12K'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4979a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "# Defining transforms for the training, validation, and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
    "print(len(train_data))\n",
    "# print(train_data[9998])\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)  #9999\n",
    "indices = list(range(dataset_size)) #[0,1,...,9998]\n",
    "split = int(np.floor(0.2 * dataset_size))  #1999\n",
    "print(split)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]  # [1999,...,9998] , [0,...,1998]\n",
    "# print((val_indices))\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "# print(type(train_sampler))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=train_sampler)\n",
    "# print(len(train_loader))\n",
    "validation_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
    "# print(*validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e62e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_CNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dense): Linear(in_features=12800, out_features=512, bias=True)\n",
      ")\n",
      "Epoch 1, Training Loss: 2.2935, Validation Loss: 2.2495, Validation Accuracy: 0.1626\n",
      "Epoch 2, Training Loss: 2.1979, Validation Loss: 2.1496, Validation Accuracy: 0.2161\n",
      "Epoch 3, Training Loss: 2.1071, Validation Loss: 2.0998, Validation Accuracy: 0.2461\n",
      "Epoch 4, Training Loss: 2.0572, Validation Loss: 2.0554, Validation Accuracy: 0.2541\n",
      "Epoch 5, Training Loss: 2.0091, Validation Loss: 2.0114, Validation Accuracy: 0.2846\n",
      "Epoch 6, Training Loss: 1.9459, Validation Loss: 1.9966, Validation Accuracy: 0.2736\n",
      "Epoch 7, Training Loss: 1.9019, Validation Loss: 1.9693, Validation Accuracy: 0.3027\n",
      "Epoch 8, Training Loss: 1.8292, Validation Loss: 2.0472, Validation Accuracy: 0.2696\n",
      "Epoch 9, Training Loss: 1.7851, Validation Loss: 1.9377, Validation Accuracy: 0.3187\n",
      "Epoch 10, Training Loss: 1.6976, Validation Loss: 1.9985, Validation Accuracy: 0.3037\n"
     ]
    }
   ],
   "source": [
    "activation_functions = {\n",
    "            'relu': F.relu,\n",
    "            'gelu': F.gelu,\n",
    "            'silu': F.silu,\n",
    "            'mish': F.mish\n",
    "        }\n",
    "\n",
    "# defining a class CNN that inherits from nn.Module which is PyTorch's base class for all neural network\n",
    "class my_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, num_filters=[32, 64, 128, 256, 512], filter_sizes=[3, 3, 3, 3, 3], activation_fn='relu', num_neurons_dense=512):\n",
    "        super(my_CNN, self).__init__()\n",
    "        # Initializing class variables\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.activation_fn = activation_functions[activation_fn]\n",
    "        self.num_neurons_dense = num_neurons_dense\n",
    "\n",
    "        # Creating convolution layers using ModuleList\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 3  # since, input images are RGB\n",
    "        for out_channels, kernel_size in zip(num_filters, filter_sizes):\n",
    "            # a convolutional layer with in-out channels and kernel size\n",
    "            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, padding=0)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            # Update in_channels for the next layer\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Placeholder for dense layer will be initialized after calculating the flatten size\n",
    "        self.dense = None\n",
    "        # output layer: maps from the dense layer to the number of classes.\n",
    "        self.out = nn.Linear(num_neurons_dense, num_classes)\n",
    "        # find the size needed to flatten the conv layer outputs, initializing the dense layer accordingly\n",
    "        self.init_flatten_size(input_shape=(3, 224, 224))  # input images are 224x224 RGB images\n",
    "        # initializing the dense layer from flatten size\n",
    "        self.dense = nn.Linear(self.flatten_size, num_neurons_dense)\n",
    "\n",
    "\n",
    "    def init_flatten_size(self, input_shape):\n",
    "        # to disable gradient calculations for speed up this computation\n",
    "        with torch.no_grad():\n",
    "            # a dummy input tensor of the correct shape\n",
    "            input_tensor = torch.zeros(1, *input_shape)\n",
    "            # Forward propagate through the conv layers to find output size\n",
    "            output = self.forward_conv_layers(input_tensor)\n",
    "            # total number of output features is the flat size needed for the dense layer input\n",
    "            self.flatten_size = output.numel()\n",
    "\n",
    "    # a function for sequentially passing input through all convolutional layers and applying activation and pooling\n",
    "    def forward_conv_layers(self, x):\n",
    "        # Convolution blocks\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)  # Convolution operation\n",
    "            x = self.activation_fn(x)  # Apply the specified activation function\n",
    "            x = F.max_pool2d(x, 2)  # Apply max pooling with a kernel size of 2\n",
    "        return x\n",
    "\n",
    "    # forward method defines how the input tensor is transformed through the model\n",
    "    def forward(self, x):\n",
    "        # Passing input through the convolution blocks\n",
    "        x = self.forward_conv_layers(x)\n",
    "        # Flattening the output for the dense layer\n",
    "        x = torch.flatten(x, 1)   # Flatten the output for the dense layer\n",
    "        # Dense layer\n",
    "        x = self.dense(x)\n",
    "        x = self.activation_fn(x)\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    # Method for training and evaluating the model\n",
    "    def train_and_evaluate(self, train_loader, validation_loader, n_epochs=10, lr=0.001, device=None):\n",
    "        if device is None:\n",
    "            # setting up CUDA if available, otherwise, using CPU\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)  # transferring the model to the selected device (GPU or CPU)\n",
    "\n",
    "        # Initializing the loss function and optimizer\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()  # Setting model to training mode\n",
    "            training_loss = 0.0\n",
    "\n",
    "            # Iterate over the training data\n",
    "            for images, labels in train_loader:\n",
    "                # transferring images and labels to the current device (GPU or CPU)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # clearing the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # Forward prop: computing predicted outputs by passing inputs to the model\n",
    "                outputs = self(images)\n",
    "                # calculating the loss between predicted and true labels\n",
    "                loss = loss_function(outputs, labels)\n",
    "                # Backward prop: computing gradient of the loss with respect to parameters\n",
    "                loss.backward()\n",
    "                # optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                # updating running training loss\n",
    "                training_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # average loss over an epoch\n",
    "            training_loss /= len(train_loader.sampler)\n",
    "\n",
    "            # Evaluation phase\n",
    "            self.eval()  # Setting model to evaluation mode\n",
    "            # initializing the validation loss for the epoch\n",
    "            validation_loss = 0.0\n",
    "            # tracking number of correctly predicted instances\n",
    "            correct = 0\n",
    "            # tracking total number of instances\n",
    "            total = 0\n",
    "            # disable gradient calculation for validation, saving memory and computations\n",
    "            with torch.no_grad():\n",
    "                # iterating over the validation data loader\n",
    "                for images, labels in validation_loader:\n",
    "                    # transferring images and labels to the current device (GPU or CPU)\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    # Forward prop: computing predicted outputs by passing inputs to the model\n",
    "                    outputs = self(images)\n",
    "                    # calculating the loss between predicted and true labels\n",
    "                    loss = loss_function(outputs, labels)\n",
    "                    # updating running validation loss\n",
    "                    validation_loss += loss.item() * images.size(0)\n",
    "                    # converting output probabilities to predicted class\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    # updating total number of instances\n",
    "                    total += labels.size(0)\n",
    "                    # updating correctly predicted instances\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # average validation loss over an epoch\n",
    "            validation_loss /= len(validation_loader.sampler)\n",
    "            # validation accuracy\n",
    "            validation_accuracy = correct / total\n",
    "\n",
    "            # printing training and validation results\n",
    "            print(f'Epoch {epoch+1}, Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n",
    "#             wandb.log({\"accuracy\": validation_accuracy, \"loss\": validation_loss})\n",
    "\n",
    "\n",
    "# model with parameters\n",
    "model = my_CNN(num_classes=10,\n",
    "                  num_filters=[32, 64, 128, 256, 512],\n",
    "                  filter_sizes=[3, 3, 3, 3, 3],\n",
    "                  activation_fn=F.relu,\n",
    "                  num_neurons_dense=512)\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.train_and_evaluate(train_loader, validation_loader, n_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c11ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your API:25c2257eaf6c22aa056893db14da4ee2bf0a531a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "import random\n",
    "\n",
    "key = input('Enter your API:')\n",
    "wandb.login(key=key)  #25c2257eaf6c22aa056893db14da4ee2bf0a531a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a8f9e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: oypngjeo\n",
      "Sweep URL: https://wandb.ai/parthasakhapaul/Deep_leraning_A2/sweeps/oypngjeo\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',  # can be grid, random\n",
    "    'name' : 'cnn1',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_filters': {\n",
    "            'values': [[32, 64, 128, 256, 512], [64, 64, 64, 64, 64]] \n",
    "        },\n",
    "        'activation_fn': {\n",
    "            'values': ['relu', 'gelu', 'silu', 'mish']\n",
    "        },\n",
    "#         'dropout': {\n",
    "#             'values': [0.2, 0.3]\n",
    "#         },\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Deep_leraning_A2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b01df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init() as run:\n",
    "        run_name = \"-ac_\"+wandb.config.activation_fn+\"-filters_\"+str(wandb.config.num_filters)\n",
    "        wandb.run.name=run_name\n",
    "        # Model training\n",
    "        model = my_CNN(num_classes=10,\n",
    "                  num_filters=wandb.config.num_filters,\n",
    "                  filter_sizes=[3, 3, 3, 3, 3],\n",
    "                  activation_fn=wandb.config.activation_fn,\n",
    "                  num_neurons_dense=512)\n",
    "        model.train_and_evaluate(train_loader, validation_loader, n_epochs=10, lr=0.001)        \n",
    "\n",
    "wandb.agent(sweep_id, function=main, count=20)  # to run 20 experiments\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1946233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05079f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3b595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
