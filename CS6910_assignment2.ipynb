{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8000604,"sourceType":"datasetVersion","datasetId":4711316}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **NAME: PARTHA SAKHA PAUL**\n\n# **ROLL: MA23M016**\n\n    CS6910_assignment 2\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision import datasets, transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport numpy as np\n\n# data_dir = '/content/drive/My Drive/nature_12K'\n\n\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n# ])\n\n# dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\n# data_dir = '/content/drive/My Drive/nature_12K/inaturalist_12K'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T16:51:43.570279Z","iopub.execute_input":"2024-04-05T16:51:43.570784Z","iopub.status.idle":"2024-04-05T16:51:50.225944Z","shell.execute_reply.started":"2024-04-05T16:51:43.570750Z","shell.execute_reply":"2024-04-05T16:51:50.225154Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def prepare_data_loaders(data_augment, batch_size=64):\n    if data_augment:\n        # With data augmentation\n        train_transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.450, 0.470, 0.490], std=[0.200, 0.220, 0.240]),\n        ])\n#         val_transform = transforms.Compose([\n#         transforms.Resize(256),\n#         transforms.CenterCrop(224),\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.450, 0.470, 0.490], std=[0.200, 0.220, 0.240]),\n#         ])\n    else:\n        # Without data augmentation\n        train_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        ])\n#         val_transform = transforms.Compose([\n#         transforms.Resize((224, 224)),\n#         transforms.ToTensor(),\n#         ])\n    \n    # Load datasets\n    train_data = datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/train', transform=train_transform)\n#     validation_dataset = datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/val', transform=val_transform)\n#     print(len(train_data))\n    # print(train_data[9998])\n    # Creating data indices for training and validation splits:\n    dataset_size = len(train_data)  #9999\n    indices = list(range(dataset_size)) #[0,1,...,9998]\n    split = int(np.floor(0.2 * dataset_size))  #1999\n#     print(split)\n    np.random.shuffle(indices)\n    train_indices, val_indices = indices[split:], indices[:split]  # [1999,...,9998] , [0,...,1998]\n    # print((val_indices))\n\n    # Creating data samplers and loaders\n    train_sampler = SubsetRandomSampler(train_indices)\n    valid_sampler = SubsetRandomSampler(val_indices)\n    # print(type(train_sampler))\n\n    train_loader = DataLoader(train_data, batch_size=64, sampler=train_sampler)\n    # print(len(train_loader))\n    validation_loader = DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n    # print(*validation_loader)\n    # Prepare data loaders\n#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n#     validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n    \n    return train_loader, validation_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-05T16:51:57.552737Z","iopub.execute_input":"2024-04-05T16:51:57.553704Z","iopub.status.idle":"2024-04-05T16:51:57.563340Z","shell.execute_reply.started":"2024-04-05T16:51:57.553671Z","shell.execute_reply":"2024-04-05T16:51:57.562411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"activation_functions = {\n            'relu': F.relu,\n            'gelu': F.gelu,\n            'silu': F.silu,\n            'mish': F.mish\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-05T16:52:00.265037Z","iopub.execute_input":"2024-04-05T16:52:00.265774Z","iopub.status.idle":"2024-04-05T16:52:00.270068Z","shell.execute_reply.started":"2024-04-05T16:52:00.265744Z","shell.execute_reply":"2024-04-05T16:52:00.269083Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # Defining transforms for the training, validation, and testing sets\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n# ])\n\n# data_dir = '/kaggle/input/inaturalist/inaturalist_12K/train'\n\n# # Load the datasets with ImageFolder\n# train_data = datasets.ImageFolder(data_dir, transform=transform)\n# print(len(train_data))\n# # print(train_data[9998])\n# # Creating data indices for training and validation splits:\n# dataset_size = len(train_data)  #9999\n# indices = list(range(dataset_size)) #[0,1,...,9998]\n# split = int(np.floor(0.2 * dataset_size))  #1999\n# print(split)\n# np.random.shuffle(indices)\n# train_indices, val_indices = indices[split:], indices[:split]  # [1999,...,9998] , [0,...,1998]\n# # print((val_indices))\n\n# # Creating data samplers and loaders\n# train_sampler = SubsetRandomSampler(train_indices)\n# valid_sampler = SubsetRandomSampler(val_indices)\n# # print(type(train_sampler))\n\n# train_loader = DataLoader(train_data, batch_size=64, sampler=train_sampler)\n# # print(len(train_loader))\n# validation_loader = DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n# # print(*validation_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:03:10.771725Z","iopub.execute_input":"2024-04-05T09:03:10.772146Z","iopub.status.idle":"2024-04-05T09:03:20.205819Z","shell.execute_reply.started":"2024-04-05T09:03:10.772112Z","shell.execute_reply":"2024-04-05T09:03:20.204865Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"9999\n1999\n","output_type":"stream"}]},{"cell_type":"code","source":"# defining a class CNN that inherits from nn.Module which is PyTorch's base class for all neural network\nclass my_CNN(nn.Module):\n    def __init__(self, num_classes=10, num_filters=[32, 64, 128, 256, 512], filter_sizes=[3, 3, 3, 3, 3], activation_fn='relu', num_neurons_dense = 512, dropout_rate = 0.5, use_batchnorm='no'):\n        super(my_CNN, self).__init__()\n        # Initializing class variables\n        self.num_classes = num_classes\n        self.num_filters = num_filters\n        self.filter_sizes = filter_sizes\n        self.activation_fn = activation_functions[activation_fn]\n        self.num_neurons_dense = num_neurons_dense\n        self.dropout_rate = dropout_rate\n        # Convert yes/no to boolean\n        self.use_batchnorm = True if use_batchnorm.lower() == 'yes' else False\n\n        # Creating convolution layers using ModuleList\n        self.conv_layers = nn.ModuleList()\n        # List to hold batchnorm layers for conv\n        self.batchnorm_layers_conv = nn.ModuleList()\n        in_channels = 3  # since, input images are RGB\n        for out_channels, kernel_size in zip(num_filters, filter_sizes):\n            # a convolution layer with in-out channels and kernel size\n            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n            self.conv_layers.append(conv_layer)\n            if self.use_batchnorm:\n                # Add a Batchnorm2d layer for each conv layer\n                self.batchnorm_layers_conv.append(nn.BatchNorm2d(out_channels))\n            # Update in_channels for the next layer\n            in_channels = out_channels\n\n            \n        # Defining dropout before it's used\n        self.dropout = nn.Dropout(dropout_rate)\n        # find the size needed to flatten the conv layer outputs, initializing the dense layer accordingly\n        self.init_flatten_size(input_shape=(3, 224, 224))  # input images are 224x224 RGB images\n        # initializing the dense layer from flatten size\n        self.dense = nn.Linear(self.flatten_size, num_neurons_dense)\n        if self.use_batchnorm:\n             # Batchnorm1d for the dense layer\n            self.batchnorm_dense = nn.BatchNorm1d(num_neurons_dense)\n        # output layer: maps from the dense layer to the number of classes.\n        self.out = nn.Linear(num_neurons_dense, num_classes)\n\n\n    def init_flatten_size(self, input_shape):\n        # to disable gradient calculations for speed up this computation\n        with torch.no_grad():\n            # a dummy input tensor of the correct shape\n            input_tensor = torch.zeros(1, *input_shape)\n            # Forward prop through the conv layers to find output size\n            output = self.forward_conv_layers(input_tensor)\n            # total number of output features is the flat size needed for the dense layer input\n            self.flatten_size = output.numel()\n\n    # a function for sequentially passing input through all convolutional layers and applying activation and pooling\n    def forward_conv_layers(self, x):\n        # Convolution layer\n        for i, conv in enumerate(self.conv_layers):\n            x = conv(x)  # Convolution operation\n            if self.use_batchnorm:\n                # Apply batchnorm if enabled\n                x = self.batchnorm_layers_conv[i](x)\n            x = self.activation_fn(x)  # Apply the specified activation function\n            x = F.max_pool2d(x, 2)  # max pooling with a kernel size of 2\n            x = self.dropout(x)  # Apply dropout after pooling\n        return x\n\n    # forward method defines how the input tensor is transformed through the model\n    def forward(self, x):\n        # Passing input through the convolution blocks\n        x = self.forward_conv_layers(x)\n        # Flattening the output for the dense layer\n        x = torch.flatten(x, 1)   # Flatten the output for the dense layer\n        # Dense layer\n        x = self.dense(x)\n        if self.use_batchnorm:\n            # Apply batchnorm if enabled to dense layer\n            x = self.batchnorm_dense(x)\n        x = self.activation_fn(x)\n        # Applying dropout before the final layer\n        x = self.dropout(x)\n        # Output layer\n        x = self.out(x)\n        return x\n    \n\n    # Method for training and evaluating the model\n    def train_and_evaluate(self, train_loader, validation_loader, n_epochs=10, lr=0.001, device=None):\n        if device is None:\n            # setting up CUDA if available, otherwise, using CPU\n            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        self.to(device)  # transferring the model to the selected device (GPU or CPU)\n\n        # Initializing the loss function and optimizer\n        loss_function = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.parameters(), lr=lr)  # self.parameters() is a built-in method provided by PyTorch's nn.Module that collects all the learnable parameters of our model\n\n        # Training loop\n        for epoch in range(n_epochs):\n            self.train()  # Setting model to training mode\n            training_loss = 0.0\n            # tracking number of correctly predicted instances\n            correct_train = 0\n            # tracking total number of instances\n            total_train = 0\n\n            # Iterate over the training data\n            for images, labels in train_loader:\n                # transferring images and labels to the current device (GPU or CPU)\n                images, labels = images.to(device), labels.to(device)\n                # clearing the gradients of all optimized variables\n                optimizer.zero_grad()\n                # Forward prop: computing predicted outputs by passing inputs to the model\n                outputs = self(images)\n                # calculating the loss between predicted and true labels\n                loss = loss_function(outputs, labels)\n                # Backward prop: computing gradient of the loss with respect to parameters\n                loss.backward()\n                # optimization step (parameter update)\n                optimizer.step()\n                # updating running training loss\n                training_loss += loss.item() * images.size(0)\n                # converting output probabilities to predicted class\n                _, predicted_train = torch.max(outputs.data, 1)\n                # updating total number of instances\n                total_train += labels.size(0)\n                # updating correctly predicted instances\n                correct_train += (predicted_train == labels).sum().item()\n\n            # average loss over an epoch\n            training_loss /= len(train_loader.sampler)\n            # train accuracy\n            train_accuracy = correct_train / total_train\n\n            # Evaluation phase\n            self.eval()  # Setting model to evaluation mode\n            # initializing the validation loss for the epoch\n            validation_loss = 0.0\n            # tracking number of correctly predicted instances\n            correct_val = 0\n            # tracking total number of instances\n            total_val = 0\n            # disable gradient calculation for validation, saving memory and computations\n            with torch.no_grad():\n                # iterating over the validation data loader\n                for images, labels in validation_loader:\n                    # transferring images and labels to the current device (GPU or CPU)\n                    images, labels = images.to(device), labels.to(device)\n                    # Forward prop: computing predicted outputs by passing inputs to the model\n                    outputs = self(images)\n                    # calculating the loss between predicted and true labels\n                    loss = loss_function(outputs, labels)\n                    # updating running validation loss\n                    validation_loss += loss.item() * images.size(0)\n                    # converting output probabilities to predicted class\n                    _, predicted = torch.max(outputs.data, 1)\n                    # updating total number of instances\n                    total_val += labels.size(0)\n                    # updating correctly predicted instances\n                    correct_val += (predicted == labels).sum().item()\n\n            # average validation loss over an epoch\n            validation_loss /= len(validation_loader.sampler)\n            # validation accuracy\n            val_accuracy = correct_val / total_val\n\n            # printing training and validation results\n            print(f'Epoch {epoch+1}, Training Loss: {training_loss:.4f}, Training Accuracy: {train_accuracy*100:.2f}, \\nValidation Loss: {validation_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}')\n            wandb.log({\"train_accuracy\": train_accuracy * 100, \"training_loss\": training_loss})\n            wandb.log({\"val_accuracy\": val_accuracy * 100, \"val_loss\": validation_loss})\n\n\n# model with parameters\nmodel = my_CNN(num_classes=10,\n                  num_filters=[32, 64, 128, 256, 512],\n                  filter_sizes=[7,9,7,9,9],\n                  activation_fn='relu',\n                  num_neurons_dense=512,\n                  dropout_rate = 0.5, \n                  use_batchnorm='yes')\n\nprint(model)\n\n# model.train_and_evaluate(train_loader, validation_loader, n_epochs=10, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T17:02:53.039841Z","iopub.execute_input":"2024-04-05T17:02:53.040177Z","iopub.status.idle":"2024-04-05T17:02:53.328619Z","shell.execute_reply.started":"2024-04-05T17:02:53.040151Z","shell.execute_reply":"2024-04-05T17:02:53.327569Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"my_CNN(\n  (conv_layers): ModuleList(\n    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(32, 64, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n    (2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n    (3): Conv2d(128, 256, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n    (4): Conv2d(256, 512, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n  )\n  (batchnorm_layers_conv): ModuleList(\n    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (dropout): Dropout(p=0.5, inplace=False)\n  (dense): Linear(in_features=512, out_features=512, bias=True)\n  (batchnorm_dense): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (out): Linear(in_features=512, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random\n\nkey = input('Enter your API:')\nwandb.login(key=key)  #25c2257eaf6c22aa056893db14da4ee2bf0a531a","metadata":{"execution":{"iopub.status.busy":"2024-04-05T16:52:11.185264Z","iopub.execute_input":"2024-04-05T16:52:11.185621Z","iopub.status.idle":"2024-04-05T16:52:19.205724Z","shell.execute_reply.started":"2024-04-05T16:52:11.185594Z","shell.execute_reply":"2024-04-05T16:52:19.204823Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your API: 25c2257eaf6c22aa056893db14da4ee2bf0a531a\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',  # can be grid, random\n    'name' : 'cnn kaggle all 2',\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'num_filters': {\n            'values': [[16, 32, 64, 128, 256], [64, 64, 64, 64, 64], [256, 128, 64, 32, 16]] \n        },\n        'filter_sizes':{\n            'values': [[3,3,3,3,3], [3,3,5,3,3], [3,5,3,5,3]]\n        },\n        'activation_fn': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'dropout': {\n            'values': [0.2, 0.3, 0.5]\n        },\n        'batch_norm':{x\n            'values': ['true','false']\n        },\n        'data_augment': {\n            'values': ['true', 'false']\n        },\n        'num_neurons_dense':{\n            'values': [64, 128, 256]\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project=\"Deep_learning_A2\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T17:02:58.115762Z","iopub.execute_input":"2024-04-05T17:02:58.116128Z","iopub.status.idle":"2024-04-05T17:03:06.788596Z","shell.execute_reply.started":"2024-04-05T17:02:58.116097Z","shell.execute_reply":"2024-04-05T17:03:06.787454Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Create sweep with ID: hso5osa8\nSweep URL: https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        run_name = \"-ac-\"+wandb.config.activation_fn+\"-filters-\"+str(wandb.config.num_filters)+\"-filt_size-\"+str(wandb.config.filter_sizes)+\"-dropout-\"+str(wandb.config.dropout)+\"-batch_norm-\"+wandb.config.batch_norm+\"-data_aug-\"+wandb.config.data_augment+\"-num_neurons_dense-\"+str(wandb.config.num_neurons_dense)\n        wandb.run.name=run_name\n        # Model object creation\n        model = my_CNN(num_classes = 10,\n                  num_filters = wandb.config.num_filters,\n                  filter_sizes = wandb.config.filter_sizes,\n                  activation_fn = wandb.config.activation_fn,\n                  num_neurons_dense = wandb.config.num_neurons_dense,\n                  dropout_rate = wandb.config.dropout,\n                  use_batchnorm = wandb.config.batch_norm)\n        \n        data_augment = wandb.config.data_augment\n        train_loader, validation_loader = prepare_data_loaders(data_augment)\n        # Model training\n        model.train_and_evaluate(train_loader, validation_loader, n_epochs=10, lr=0.001)        \n\nwandb.agent(sweep_id, function=main, count=10)  # to run 5 experiments\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T17:03:11.522259Z","iopub.execute_input":"2024-04-05T17:03:11.522622Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ncgek4sw with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 5, 3, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [16, 32, 64, 128, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_170313-ncgek4sw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ncgek4sw' target=\"_blank\">skilled-sweep-1</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ncgek4sw' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ncgek4sw</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2494, Training Accuracy: 16.51, \nValidation Loss: 2.2277, Validation Accuracy: 17.56\nEpoch 2, Training Loss: 2.1907, Training Accuracy: 19.48, \nValidation Loss: 2.1591, Validation Accuracy: 19.01\nEpoch 3, Training Loss: 2.1522, Training Accuracy: 21.14, \nValidation Loss: 2.1952, Validation Accuracy: 19.66\nEpoch 4, Training Loss: 2.1171, Training Accuracy: 22.69, \nValidation Loss: 2.1397, Validation Accuracy: 20.66\nEpoch 5, Training Loss: 2.1050, Training Accuracy: 24.11, \nValidation Loss: 2.1016, Validation Accuracy: 24.26\nEpoch 6, Training Loss: 2.0828, Training Accuracy: 25.25, \nValidation Loss: 2.1299, Validation Accuracy: 24.51\nEpoch 7, Training Loss: 2.0764, Training Accuracy: 25.14, \nValidation Loss: 2.0650, Validation Accuracy: 25.71\nEpoch 8, Training Loss: 2.0565, Training Accuracy: 25.87, \nValidation Loss: 2.0664, Validation Accuracy: 24.71\nEpoch 9, Training Loss: 2.0338, Training Accuracy: 26.70, \nValidation Loss: 2.0946, Validation Accuracy: 23.91\nEpoch 10, Training Loss: 2.0237, Training Accuracy: 27.14, \nValidation Loss: 2.0819, Validation Accuracy: 25.31\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▃▄▅▆▇▇▇██</td></tr><tr><td>training_loss</td><td>█▆▅▄▄▃▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▇▇█▇▆█</td></tr><tr><td>val_loss</td><td>█▅▇▄▃▄▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>27.1375</td></tr><tr><td>training_loss</td><td>2.0237</td></tr><tr><td>val_accuracy</td><td>25.31266</td></tr><tr><td>val_loss</td><td>2.08188</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">skilled-sweep-1</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ncgek4sw' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ncgek4sw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_170313-ncgek4sw/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nzjoqa3a with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: silu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 5, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [64, 64, 64, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_172154-nzjoqa3a</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/nzjoqa3a' target=\"_blank\">pretty-sweep-2</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/nzjoqa3a' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/nzjoqa3a</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2282, Training Accuracy: 17.03, \nValidation Loss: 2.1593, Validation Accuracy: 20.91\nEpoch 2, Training Loss: 2.1336, Training Accuracy: 22.69, \nValidation Loss: 2.1176, Validation Accuracy: 23.06\nEpoch 3, Training Loss: 2.1058, Training Accuracy: 24.41, \nValidation Loss: 2.0977, Validation Accuracy: 23.76\nEpoch 4, Training Loss: 2.0597, Training Accuracy: 26.01, \nValidation Loss: 2.0773, Validation Accuracy: 25.06\nEpoch 5, Training Loss: 2.0363, Training Accuracy: 27.15, \nValidation Loss: 2.0380, Validation Accuracy: 27.01\nEpoch 6, Training Loss: 2.0298, Training Accuracy: 27.32, \nValidation Loss: 2.0541, Validation Accuracy: 25.16\nEpoch 7, Training Loss: 2.0173, Training Accuracy: 27.95, \nValidation Loss: 2.0323, Validation Accuracy: 26.96\nEpoch 8, Training Loss: 1.9941, Training Accuracy: 28.98, \nValidation Loss: 1.9924, Validation Accuracy: 29.01\nEpoch 9, Training Loss: 1.9900, Training Accuracy: 29.65, \nValidation Loss: 1.9759, Validation Accuracy: 29.81\nEpoch 10, Training Loss: 1.9744, Training Accuracy: 30.01, \nValidation Loss: 1.9661, Validation Accuracy: 30.12\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>training_loss</td><td>█▅▅▃▃▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▄▆▄▆▇██</td></tr><tr><td>val_loss</td><td>█▆▆▅▄▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>30.0125</td></tr><tr><td>training_loss</td><td>1.97441</td></tr><tr><td>val_accuracy</td><td>30.11506</td></tr><tr><td>val_loss</td><td>1.96605</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pretty-sweep-2</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/nzjoqa3a' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/nzjoqa3a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_172154-nzjoqa3a/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ogzkxh8s with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 5, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [256, 128, 64, 32, 16]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_174144-ogzkxh8s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ogzkxh8s' target=\"_blank\">feasible-sweep-3</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ogzkxh8s' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ogzkxh8s</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.3052, Training Accuracy: 10.59, \nValidation Loss: 2.2991, Validation Accuracy: 10.71\nEpoch 2, Training Loss: 2.2906, Training Accuracy: 11.43, \nValidation Loss: 2.2919, Validation Accuracy: 12.56\nEpoch 3, Training Loss: 2.2568, Training Accuracy: 15.11, \nValidation Loss: 2.2448, Validation Accuracy: 18.61\nEpoch 4, Training Loss: 2.2160, Training Accuracy: 16.71, \nValidation Loss: 2.2229, Validation Accuracy: 17.61\nEpoch 5, Training Loss: 2.1991, Training Accuracy: 18.52, \nValidation Loss: 2.2701, Validation Accuracy: 12.21\nEpoch 6, Training Loss: 2.1883, Training Accuracy: 19.51, \nValidation Loss: 2.2100, Validation Accuracy: 18.46\nEpoch 7, Training Loss: 2.1656, Training Accuracy: 19.81, \nValidation Loss: 2.2227, Validation Accuracy: 16.81\nEpoch 8, Training Loss: 2.1630, Training Accuracy: 19.64, \nValidation Loss: 2.2517, Validation Accuracy: 14.56\nEpoch 9, Training Loss: 2.1590, Training Accuracy: 20.60, \nValidation Loss: 2.1640, Validation Accuracy: 21.16\nEpoch 10, Training Loss: 2.1472, Training Accuracy: 20.77, \nValidation Loss: 2.1936, Validation Accuracy: 17.81\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.048 MB uploaded\\r'), FloatProgress(value=0.02737937446833765, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▄▅▆▇▇▇██</td></tr><tr><td>training_loss</td><td>█▇▆▄▃▃▂▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▂▆▆▂▆▅▄█▆</td></tr><tr><td>val_loss</td><td>██▅▄▇▃▄▆▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>20.775</td></tr><tr><td>training_loss</td><td>2.14721</td></tr><tr><td>val_accuracy</td><td>17.8089</td></tr><tr><td>val_loss</td><td>2.1936</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">feasible-sweep-3</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ogzkxh8s' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/ogzkxh8s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_174144-ogzkxh8s/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t526w7yv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 5, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [16, 32, 64, 128, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_180609-t526w7yv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/t526w7yv' target=\"_blank\">valiant-sweep-4</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/t526w7yv' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/t526w7yv</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2282, Training Accuracy: 16.59, \nValidation Loss: 2.2983, Validation Accuracy: 13.26\nEpoch 2, Training Loss: 2.1589, Training Accuracy: 21.22, \nValidation Loss: 2.2342, Validation Accuracy: 18.71\nEpoch 3, Training Loss: 2.1190, Training Accuracy: 23.79, \nValidation Loss: 2.0969, Validation Accuracy: 24.96\nEpoch 4, Training Loss: 2.0938, Training Accuracy: 23.99, \nValidation Loss: 2.3118, Validation Accuracy: 16.81\nEpoch 5, Training Loss: 2.0557, Training Accuracy: 26.17, \nValidation Loss: 2.0998, Validation Accuracy: 24.76\nEpoch 6, Training Loss: 2.0362, Training Accuracy: 26.54, \nValidation Loss: 2.0768, Validation Accuracy: 26.86\nEpoch 7, Training Loss: 2.0282, Training Accuracy: 27.22, \nValidation Loss: 2.1408, Validation Accuracy: 22.76\nEpoch 8, Training Loss: 2.0165, Training Accuracy: 27.66, \nValidation Loss: 2.1476, Validation Accuracy: 22.86\nEpoch 9, Training Loss: 2.0063, Training Accuracy: 27.71, \nValidation Loss: 1.9469, Validation Accuracy: 31.32\nEpoch 10, Training Loss: 1.9898, Training Accuracy: 28.90, \nValidation Loss: 2.0412, Validation Accuracy: 28.61\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▅▆▇▇▇▇█</td></tr><tr><td>training_loss</td><td>█▆▅▄▃▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▂▅▆▅▅█▇</td></tr><tr><td>val_loss</td><td>█▇▄█▄▃▅▅▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>28.9</td></tr><tr><td>training_loss</td><td>1.98977</td></tr><tr><td>val_accuracy</td><td>28.61431</td></tr><tr><td>val_loss</td><td>2.0412</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">valiant-sweep-4</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/t526w7yv' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/t526w7yv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_180609-t526w7yv/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0v8mpx1f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 5, 3, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [64, 64, 64, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_182443-0v8mpx1f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/0v8mpx1f' target=\"_blank\">charmed-sweep-5</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/0v8mpx1f' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/0v8mpx1f</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2208, Training Accuracy: 17.60, \nValidation Loss: 2.1836, Validation Accuracy: 17.76\nEpoch 2, Training Loss: 2.1512, Training Accuracy: 21.32, \nValidation Loss: 2.1409, Validation Accuracy: 22.06\nEpoch 3, Training Loss: 2.1249, Training Accuracy: 23.74, \nValidation Loss: 2.0917, Validation Accuracy: 23.86\nEpoch 4, Training Loss: 2.1066, Training Accuracy: 24.14, \nValidation Loss: 2.0777, Validation Accuracy: 25.31\nEpoch 5, Training Loss: 2.0822, Training Accuracy: 25.56, \nValidation Loss: 2.0429, Validation Accuracy: 27.41\nEpoch 6, Training Loss: 2.0838, Training Accuracy: 25.94, \nValidation Loss: 2.0478, Validation Accuracy: 25.81\nEpoch 7, Training Loss: 2.0629, Training Accuracy: 26.39, \nValidation Loss: 2.0077, Validation Accuracy: 28.71\nEpoch 8, Training Loss: 2.0448, Training Accuracy: 27.10, \nValidation Loss: 2.0461, Validation Accuracy: 26.86\nEpoch 9, Training Loss: 2.0356, Training Accuracy: 26.95, \nValidation Loss: 2.0271, Validation Accuracy: 27.91\nEpoch 10, Training Loss: 2.0161, Training Accuracy: 27.46, \nValidation Loss: 2.0192, Validation Accuracy: 28.31\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>training_loss</td><td>█▆▅▄▃▃▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▆█▇▇█</td></tr><tr><td>val_loss</td><td>█▆▄▄▂▃▁▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>27.4625</td></tr><tr><td>training_loss</td><td>2.01611</td></tr><tr><td>val_accuracy</td><td>28.31416</td></tr><tr><td>val_loss</td><td>2.01916</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">charmed-sweep-5</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/0v8mpx1f' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/0v8mpx1f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_182443-0v8mpx1f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tpai7t4d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 5, 3, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [64, 64, 64, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_184428-tpai7t4d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/tpai7t4d' target=\"_blank\">eager-sweep-6</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/tpai7t4d' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/tpai7t4d</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2195, Training Accuracy: 18.41, \nValidation Loss: 2.1224, Validation Accuracy: 22.86\nEpoch 2, Training Loss: 2.1489, Training Accuracy: 22.21, \nValidation Loss: 2.0809, Validation Accuracy: 24.81\nEpoch 3, Training Loss: 2.1136, Training Accuracy: 23.56, \nValidation Loss: 2.0945, Validation Accuracy: 24.16\nEpoch 4, Training Loss: 2.0997, Training Accuracy: 24.25, \nValidation Loss: 2.0332, Validation Accuracy: 26.61\nEpoch 5, Training Loss: 2.0724, Training Accuracy: 25.66, \nValidation Loss: 2.0186, Validation Accuracy: 28.76\nEpoch 6, Training Loss: 2.0616, Training Accuracy: 26.26, \nValidation Loss: 2.0098, Validation Accuracy: 29.46\nEpoch 7, Training Loss: 2.0632, Training Accuracy: 26.12, \nValidation Loss: 2.0299, Validation Accuracy: 30.32\nEpoch 8, Training Loss: 2.0437, Training Accuracy: 27.34, \nValidation Loss: 2.0092, Validation Accuracy: 30.37\nEpoch 9, Training Loss: 2.0477, Training Accuracy: 26.41, \nValidation Loss: 1.9582, Validation Accuracy: 30.92\nEpoch 10, Training Loss: 2.0168, Training Accuracy: 28.06, \nValidation Loss: 1.9632, Validation Accuracy: 30.47\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▅▆▇▇▇▇█</td></tr><tr><td>training_loss</td><td>█▆▄▄▃▃▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▂▄▆▇▇███</td></tr><tr><td>val_loss</td><td>█▆▇▄▄▃▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>28.0625</td></tr><tr><td>training_loss</td><td>2.0168</td></tr><tr><td>val_accuracy</td><td>30.46523</td></tr><tr><td>val_loss</td><td>1.96325</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-sweep-6</strong> at: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/tpai7t4d' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/tpai7t4d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_184428-tpai7t4d/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e85o3cmc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 5, 3, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [64, 64, 64, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_190419-e85o3cmc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/e85o3cmc' target=\"_blank\">dainty-sweep-7</a></strong> to <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/sweeps/hso5osa8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/e85o3cmc' target=\"_blank\">https://wandb.ai/parthasakhapaul/Deep_learning_A2/runs/e85o3cmc</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 2.2314, Training Accuracy: 17.31, \nValidation Loss: 2.2029, Validation Accuracy: 19.86\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}