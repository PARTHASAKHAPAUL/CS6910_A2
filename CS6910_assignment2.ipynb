{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e23769",
   "metadata": {},
   "source": [
    "# **NAME: PARTHA SAKHA PAUL**\n",
    "\n",
    "# **ROLL: MA23M016**\n",
    "\n",
    "    CS6910_assignment 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730789c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# data_dir = '/content/drive/My Drive/nature_12K'\n",
    "data_dir = 'inaturalist_12K'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# data_dir = '/content/drive/My Drive/nature_12K/inaturalist_12K'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4979a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "# Defining transforms for the training, validation, and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
    "print(len(train_data))\n",
    "# print(train_data[9998])\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)  #9999\n",
    "indices = list(range(dataset_size)) #[0,1,...,9998]\n",
    "split = int(np.floor(0.2 * dataset_size))  #1999\n",
    "print(split)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]  # [1999,...,9998] , [0,...,1998]\n",
    "# print((val_indices))\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "# print(type(train_sampler))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=train_sampler)\n",
    "# print(len(train_loader))\n",
    "validation_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
    "# print(*validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e62e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_CNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dense): Linear(in_features=12800, out_features=512, bias=True)\n",
      ")\n",
      "Epoch 1, Training Loss: 1.8340, Validation Loss: 0.4482, Validation Accuracy: 0.1631\n",
      "Epoch 2, Training Loss: 1.7743, Validation Loss: 0.4374, Validation Accuracy: 0.1901\n",
      "Epoch 3, Training Loss: 1.6955, Validation Loss: 0.4133, Validation Accuracy: 0.2531\n",
      "Epoch 4, Training Loss: 1.6288, Validation Loss: 0.3991, Validation Accuracy: 0.2701\n",
      "Epoch 5, Training Loss: 1.5854, Validation Loss: 0.3951, Validation Accuracy: 0.2821\n",
      "Epoch 6, Training Loss: 1.5357, Validation Loss: 0.3945, Validation Accuracy: 0.2991\n",
      "Epoch 7, Training Loss: 1.4963, Validation Loss: 0.3839, Validation Accuracy: 0.3092\n",
      "Epoch 8, Training Loss: 1.4429, Validation Loss: 0.3797, Validation Accuracy: 0.3167\n",
      "Epoch 9, Training Loss: 1.3757, Validation Loss: 0.3873, Validation Accuracy: 0.3172\n",
      "Epoch 10, Training Loss: 1.3027, Validation Loss: 0.3996, Validation Accuracy: 0.3427\n"
     ]
    }
   ],
   "source": [
    "# defining a class CNN that inherits from nn.Module which is PyTorch's base class for all neural network\n",
    "class my_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, num_filters=[32, 64, 128, 256, 512], filter_sizes=[3, 3, 3, 3, 3], activation_fn=F.relu, num_neurons_dense=512):\n",
    "        super(my_CNN, self).__init__()\n",
    "        # Initializing class variables\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.activation_fn = activation_fn\n",
    "        self.num_neurons_dense = num_neurons_dense\n",
    "\n",
    "        # Creating convolution layers using ModuleList\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 3  # since, input images are RGB\n",
    "        for out_channels, kernel_size in zip(num_filters, filter_sizes):\n",
    "            # a convolutional layer with in-out channels and kernel size\n",
    "            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, padding=0)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            # Update in_channels for the next layer\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Placeholder for dense layer will be initialized after calculating the flatten size\n",
    "        self.dense = None\n",
    "        # output layer: maps from the dense layer to the number of classes.\n",
    "        self.out = nn.Linear(num_neurons_dense, num_classes)\n",
    "        # find the size needed to flatten the conv layer outputs, initializing the dense layer accordingly\n",
    "        self.init_flatten_size(input_shape=(3, 224, 224))  # input images are 224x224 RGB images\n",
    "        # initializing the dense layer from flatten size\n",
    "        self.dense = nn.Linear(self.flatten_size, num_neurons_dense)\n",
    "\n",
    "\n",
    "    def init_flatten_size(self, input_shape):\n",
    "        # to disable gradient calculations for speed up this computation\n",
    "        with torch.no_grad():\n",
    "            # a dummy input tensor of the correct shape\n",
    "            input_tensor = torch.zeros(1, *input_shape)\n",
    "            # Forward propagate through the conv layers to find output size\n",
    "            output = self.forward_conv_layers(input_tensor)\n",
    "            # total number of output features is the flat size needed for the dense layer input\n",
    "            self.flatten_size = output.numel()\n",
    "\n",
    "    # a function for sequentially passing input through all convolutional layers and applying activation and pooling\n",
    "    def forward_conv_layers(self, x):\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)\n",
    "            x = self.activation_fn(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution blocks\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)\n",
    "            x = self.activation_fn(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Flattening the output for the dense layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Dense layer\n",
    "        x = self.dense(x)\n",
    "        x = self.activation_fn(x)\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def train_and_evaluate(self, train_loader, validation_loader, n_epochs=10, lr=0.001, device=None):\n",
    "        if device is None:\n",
    "            # Automatically use CUDA if available, otherwise fall back to CPU\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        # Initializing the loss function and optimizer\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            self.train()  # Setting model to training mode\n",
    "            training_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.item() * images.size(0)\n",
    "\n",
    "            training_loss /= len(train_loader.dataset)\n",
    "\n",
    "            # Evaluation phase\n",
    "            self.eval()  # Setting model to evaluation mode\n",
    "            validation_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in validation_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = self(images)\n",
    "                    loss = loss_function(outputs, labels)\n",
    "                    validation_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            validation_loss /= len(validation_loader.dataset)\n",
    "            validation_accuracy = correct / total\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n",
    "            # wandb.log({\"accuracy\": validation_accuracy, \"loss\": validation_loss})\n",
    "\n",
    "\n",
    "# model with parameters\n",
    "model = my_CNN(num_classes=10,\n",
    "                  num_filters=[32, 64, 128, 256, 512],\n",
    "                  filter_sizes=[3, 3, 3, 3, 3],\n",
    "                  activation_fn=F.relu,\n",
    "                  num_neurons_dense=512)\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.train_and_evaluate(train_loader, validation_loader, n_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c11ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
